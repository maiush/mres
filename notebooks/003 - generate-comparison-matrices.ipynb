{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a neat implementation of PairS I want a set of comparison matrices of shape (n_subset, n_example, n_example). The number of subsets is the partition on which we actually run PairS and calculate agreement with human evaluators e.g., each actual news article or prompt for story generation. The number of examples is the number of individual summaries/stories we're performing pariwise comparisons with, for each subset.\n",
    "\n",
    "These can be boolean e.g., an entry P[i, j] == 0 if example i is preferable to example j, and 1 if example j is preferable to example i, or they can store actual probabilities.\n",
    "\n",
    "Equality, or no preference, is something I need to come back to in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../utils\")\n",
    "from constants import *\n",
    "from helper import get_id_dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "n_subset_dict = {\n",
    "    \"newsroom\": 60,\n",
    "    \"summeval\": 100\n",
    "}\n",
    "n_example_dict = {\n",
    "    \"newsroom\": 7,\n",
    "    \"summeval\": 16\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"newsroom\", \"summeval\"]:\n",
    "    id_dict = get_id_dict(dataset)\n",
    "    data = pd.read_json(f\"{gdrive_path}/model_harvesting/prompts/{dataset}-theirs-compare.jsonl\", orient=\"records\", lines=True)\n",
    "    aspects = [c[c.index(\"-\")+1:] for c in data.columns if c.startswith(\"prompt\")]\n",
    "\n",
    "    for aspect in aspects:\n",
    "        comparisons = np.zeros((n_subset_dict[dataset], n_example_dict[dataset], n_example_dict[dataset])) + 0.5\n",
    "        for subset_ix, (subset_id, example_ids) in enumerate(id_dict.items()):\n",
    "            for example1 in example_ids:\n",
    "                example1_ix = example_ids.index(example1)\n",
    "                for example2 in example_ids:\n",
    "                    example2_ix = example_ids.index(example2)\n",
    "                    condition = data[\"article_id\"] == subset_id\n",
    "                    condition = condition & (data[\"system_id\"].apply(lambda x: x==[example1, example2]))\n",
    "                    s1, s2 = data.loc[condition, aspect].item()\n",
    "                    if s1 > s2:\n",
    "                        comparisons[subset_ix, example1_ix, example2_ix] = 1\n",
    "                        comparisons[subset_ix, example2_ix, example1_ix] = 0\n",
    "                    elif s1 < s2:\n",
    "                        comparisons[subset_ix, example1_ix, example2_ix] = 0\n",
    "                        comparisons[subset_ix, example2_ix, example1_ix] = 1\n",
    "\n",
    "        outfile = open(f\"../comparison_matrices/human/{dataset}-{aspect}.pickle\", \"wb\")\n",
    "        pickle.dump(comparisons, outfile); outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### direct scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"newsroom\"\n",
    "id_dict = get_id_dict(dataset)\n",
    "\n",
    "for model_name in [\"llama2\", \"llama3\", \"mistral\"]:\n",
    "    for aspect in [\"consistency\", \"coherence\", \"fluency\", \"relevance\"]:\n",
    "        data = pd.read_json(f\"{gdrive_path}/model_harvesting/{model_name}/scores/{aspect}.jsonl\", orient=\"records\", lines=True)\n",
    "        comparisons = np.zeros((n_subset_dict[dataset], n_example_dict[dataset], n_example_dict[dataset])) + 0.5\n",
    "        for subset_ix, (subset_id, example_ids) in enumerate(id_dict.items()):\n",
    "            _condition = data[\"article_id\"] == subset_id\n",
    "            for example1 in example_ids:\n",
    "                example1_ix = example_ids.index(example1)\n",
    "                s1 = data.loc[_condition&(data[\"system_id\"] == example1), \"score\"].item()\n",
    "                for example2 in example_ids:\n",
    "                    example2_ix = example_ids.index(example2)\n",
    "                    s2 = data.loc[_condition&(data[\"system_id\"] == example2), \"score\"].item()\n",
    "                    if s1 > s2:\n",
    "                        comparisons[subset_ix, example1_ix, example2_ix] = 1\n",
    "                        comparisons[subset_ix, example2_ix, example1_ix] = 0\n",
    "                    elif s1 < s2:\n",
    "                        comparisons[subset_ix, example1_ix, example2_ix] = 0\n",
    "                        comparisons[subset_ix, example2_ix, example1_ix] = 1\n",
    "        outfile = open(f\"../comparison_matrices/{model_name}/scores-{dataset}-{aspect}.pickle\", \"wb\")\n",
    "        pickle.dump(comparisons, outfile); outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"newsroom\"\n",
    "id_dict = get_id_dict(dataset)\n",
    "\n",
    "for model_name in [\"llama2\", \"llama3\", \"mistral\"]:\n",
    "    for aspect in [\"consistency\", \"coherence\", \"fluency\", \"relevance\"]:\n",
    "        data = pd.read_json(f\"{gdrive_path}/model_harvesting/{model_name}/logits_short/{aspect}.jsonl\", orient=\"records\", lines=True)\n",
    "        comparisons = np.zeros((n_subset_dict[dataset], n_example_dict[dataset], n_example_dict[dataset])) + 0.5\n",
    "        for subset_ix, (subset_id, example_ids) in enumerate(id_dict.items()):\n",
    "            _condition = data[\"article_id\"] == subset_id\n",
    "            for example1 in example_ids:\n",
    "                example1_ix = example_ids.index(example1)\n",
    "                for example2 in example_ids:\n",
    "                    example2_ix = example_ids.index(example2)\n",
    "                    if example1 == example2: continue\n",
    "                    condition = _condition & (data[\"system_id\"].apply(lambda x: x==[example1, example2]))\n",
    "                    p = data.loc[condition, [\"p_s1\", \"p_s2\"]].values\n",
    "                    if len(p) == 0:\n",
    "                        condition = _condition & (data[\"system_id\"].apply(lambda x: x==[example2, example1]))\n",
    "                        p = data.loc[condition, [\"p_s1\", \"p_s2\"]].values\n",
    "                    p_s1, p_s2 = p[0]\n",
    "                    comparisons[subset_ix, example1_ix, example2_ix] = p_s1\n",
    "                    comparisons[subset_ix, example2_ix, example1_ix] = p_s2\n",
    "        outfile = open(f\"../comparison_matrices/{model_name}/logits-short-{dataset}-{aspect}.pickle\", \"wb\")\n",
    "        pickle.dump(comparisons, outfile); outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pairs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
