{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../utils\")\n",
    "from constants import *\n",
    "from prompt_templates import *\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = [\"coherence\", \"consistency\", \"fluency\", \"relevance\"]\n",
    "columns = [\"article_id\", \"system_id\", \"article\", \"summary1\", \"summary2\"]\n",
    "columns += aspects\n",
    "columns += [f\"prompt-{aspect}\" for aspect in aspects]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### newsroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{gdrive_path}/data/newsroom/newsroom-processed.jsonl\"\n",
    "summaries = pd.read_json(path, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = pd.DataFrame(columns=columns)\n",
    "for article in summaries.article_id.unique():\n",
    "    subset = summaries.loc[summaries.article_id == article, :]\n",
    "    assert subset[\"system_id\"].nunique() == 7\n",
    "    assert subset[\"article\"].nunique() == 1\n",
    "    for summary1_id in subset[\"system_id\"].unique():\n",
    "        for summary2_id in subset[\"system_id\"].unique():\n",
    "            row = [article, (summary1_id, summary2_id), subset[\"article\"].iloc[0]]\n",
    "            summary1 = subset.loc[subset[\"system_id\"] == summary1_id, \"summary\"].item()\n",
    "            summary2 = subset.loc[subset[\"system_id\"] == summary2_id, \"summary\"].item()\n",
    "            row.append(summary1)\n",
    "            row.append(summary2)\n",
    "            prompts = []\n",
    "            for aspect in aspects:\n",
    "                s1 = subset.loc[subset[\"system_id\"] == summary1_id, aspect].item()\n",
    "                s2 = subset.loc[subset[\"system_id\"] == summary2_id, aspect].item()\n",
    "                row.append((round(s1, 2), round(s2, 2)))\n",
    "                prompt = theirs_compare_llama3.format(\n",
    "                    INSTRUCTION=instructions[aspect],\n",
    "                    ARTICLE=subset[\"article\"].iloc[0],\n",
    "                    SUMMARY1=summary1,\n",
    "                    SUMMARY2=summary2,\n",
    "                    ASPECT=aspect\n",
    "                )\n",
    "                prompts.append(prompt)\n",
    "            row.extend(prompts)\n",
    "            comparisons.loc[len(comparisons)] = row\n",
    "comparisons.to_json(f\"{gdrive_path}/model_harvesting/prompts/newsroom-theirs-compare-llama3.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for choice in [\"1\", \"2\"]:\n",
    "    comparisons = pd.DataFrame(columns=columns)\n",
    "    for article in summaries.article_id.unique():\n",
    "        subset = summaries.loc[summaries.article_id == article, :]\n",
    "        assert subset[\"system_id\"].nunique() == 7\n",
    "        assert subset[\"article\"].nunique() == 1\n",
    "        for summary1_id in subset[\"system_id\"].unique():\n",
    "            for summary2_id in subset[\"system_id\"].unique():\n",
    "                row = [article, (summary1_id, summary2_id), subset[\"article\"].iloc[0]]\n",
    "                summary1 = subset.loc[subset[\"system_id\"] == summary1_id, \"summary\"].item()\n",
    "                summary2 = subset.loc[subset[\"system_id\"] == summary2_id, \"summary\"].item()\n",
    "                row.append(summary1)\n",
    "                row.append(summary2)\n",
    "                prompts = []\n",
    "                for aspect in aspects:\n",
    "                    s1 = subset.loc[subset[\"system_id\"] == summary1_id, aspect].item()\n",
    "                    s2 = subset.loc[subset[\"system_id\"] == summary2_id, aspect].item()\n",
    "                    row.append((round(s1, 2), round(s2, 2)))\n",
    "                    prompt = mine_compare_llama3.format(\n",
    "                        INSTRUCTION=instructions[aspect],\n",
    "                        ARTICLE=subset[\"article\"].iloc[0],\n",
    "                        SUMMARY1=summary1,\n",
    "                        SUMMARY2=summary2,\n",
    "                        ASPECT=aspect,\n",
    "                        CHOICE=choice\n",
    "                    )\n",
    "                    prompts.append(prompt)\n",
    "                row.extend(prompts)\n",
    "                comparisons.loc[len(comparisons)] = row\n",
    "    comparisons.to_json(f\"{gdrive_path}/model_harvesting/prompts/newsroom-mine-compare-{choice}-llama3.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aspect in aspects:\n",
    "    prompts = []\n",
    "    for _, row in summaries.iterrows():\n",
    "        prompt = theirs_score_llama3.format(\n",
    "            INSTRUCTION=instructions[aspect],\n",
    "            ARTICLE=row[\"article\"],\n",
    "            SUMMARY=row[\"summary\"],\n",
    "            ASPECT=aspect\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "    summaries[f\"prompt-{aspect}\"] = prompts\n",
    "summaries.to_json(f\"{gdrive_path}/model_harvesting/prompts/newsroom-theirs-score-llama3.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{gdrive_path}/data/summeval/summeval-processed.jsonl\"\n",
    "summaries = pd.read_json(path, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = pd.DataFrame(columns=columns)\n",
    "for article in summaries.article_id.unique():\n",
    "    subset = summaries.loc[summaries.article_id == article, :]\n",
    "    assert subset[\"model_id\"].nunique() == 16\n",
    "    assert subset[\"article\"].nunique() == 1\n",
    "    for summary1_id in subset[\"model_id\"].unique():\n",
    "        for summary2_id in subset[\"model_id\"].unique():\n",
    "            row = [article, (summary1_id, summary2_id), subset[\"article\"].iloc[0]]\n",
    "            summary1 = subset.loc[subset[\"model_id\"] == summary1_id, \"summary\"].item()\n",
    "            summary2 = subset.loc[subset[\"model_id\"] == summary2_id, \"summary\"].item()\n",
    "            row.append(summary1)\n",
    "            row.append(summary2)\n",
    "            prompts = []\n",
    "            for aspect in aspects:\n",
    "                s1 = subset.loc[subset[\"model_id\"] == summary1_id, aspect].item()\n",
    "                s2 = subset.loc[subset[\"model_id\"] == summary2_id, aspect].item()\n",
    "                row.append((round(s1, 2), round(s2, 2)))\n",
    "                prompt = theirs_compare_llama3.format(\n",
    "                    INSTRUCTION=instructions[aspect],\n",
    "                    ARTICLE=subset[\"article\"].iloc[0],\n",
    "                    SUMMARY1=summary1,\n",
    "                    SUMMARY2=summary2,\n",
    "                    ASPECT=aspect\n",
    "                )\n",
    "                prompts.append(prompt)\n",
    "            row.extend(prompts)\n",
    "            comparisons.loc[len(comparisons)] = row\n",
    "comparisons.to_json(f\"{gdrive_path}/model_harvesting/prompts/summeval-theirs-compare-llama3.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1: 100%|██████████| 100/100 [07:00<00:00,  4.20s/it]\n",
      "2: 100%|██████████| 100/100 [07:15<00:00,  4.35s/it]\n"
     ]
    }
   ],
   "source": [
    "for choice in [\"1\", \"2\"]:\n",
    "    comparisons = pd.DataFrame(columns=columns)\n",
    "    for article in tqdm(summaries.article_id.unique(), desc=choice):\n",
    "        subset = summaries.loc[summaries.article_id == article, :]\n",
    "        assert subset[\"model_id\"].nunique() == 16\n",
    "        assert subset[\"article\"].nunique() == 1\n",
    "        for summary1_id in subset[\"model_id\"].unique():\n",
    "            for summary2_id in subset[\"model_id\"].unique():\n",
    "                row = [article, (summary1_id, summary2_id), subset[\"article\"].iloc[0]]\n",
    "                summary1 = subset.loc[subset[\"model_id\"] == summary1_id, \"summary\"].item()\n",
    "                summary2 = subset.loc[subset[\"model_id\"] == summary2_id, \"summary\"].item()\n",
    "                row.append(summary1)\n",
    "                row.append(summary2)\n",
    "                prompts = []\n",
    "                for aspect in aspects:\n",
    "                    s1 = subset.loc[subset[\"model_id\"] == summary1_id, aspect].item()\n",
    "                    s2 = subset.loc[subset[\"model_id\"] == summary2_id, aspect].item()\n",
    "                    row.append((round(s1, 2), round(s2, 2)))\n",
    "                    prompt = mine_compare_llama3.format(\n",
    "                        INSTRUCTION=instructions[aspect],\n",
    "                        ARTICLE=subset[\"article\"].iloc[0],\n",
    "                        SUMMARY1=summary1,\n",
    "                        SUMMARY2=summary2,\n",
    "                        ASPECT=aspect,\n",
    "                        CHOICE=choice\n",
    "                    )\n",
    "                    prompts.append(prompt)\n",
    "                row.extend(prompts)\n",
    "                comparisons.loc[len(comparisons)] = row\n",
    "    comparisons.to_json(f\"{gdrive_path}/model_harvesting/prompts/summeval-mine-compare-{choice}-llama3.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aspect in aspects:\n",
    "    prompts = []\n",
    "    for _, row in summaries.iterrows():\n",
    "        prompt = theirs_score_llama3.format(\n",
    "            INSTRUCTION=instructions[aspect],\n",
    "            ARTICLE=row[\"article\"],\n",
    "            SUMMARY=row[\"summary\"],\n",
    "            ASPECT=aspect\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "    summaries[f\"prompt-{aspect}\"] = prompts\n",
    "summaries.to_json(f\"{gdrive_path}/model_harvesting/prompts/summeval-theirs-score-llama3.jsonl\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pairs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
