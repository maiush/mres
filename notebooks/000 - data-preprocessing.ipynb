{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../utils\")\n",
    "from constants import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsroom\n",
    "\n",
    "path = f\"{gdrive_path}/data/newsroom\"\n",
    "df = pd.read_csv(f\"{path}/newsroom-human-eval.csv\")\n",
    "df.drop(columns=[\"ArticleTitle\"], inplace=True)\n",
    "column_mapping = {\n",
    "    \"ArticleID\": \"article_id\",\n",
    "    \"System\": \"system_id\",\n",
    "    \"ArticleText\": \"article\",\n",
    "    \"SystemSummary\": \"summary\",\n",
    "    \"CoherenceRating\": \"coherence\",\n",
    "    \"FluencyRating\": \"fluency\",\n",
    "    \"InformativenessRating\": \"consistency\",\n",
    "    \"RelevanceRating\": \"relevance\"\n",
    "}\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "df[\"system_id\"] = df.system_id.factorize()[0]\n",
    "\n",
    "out = pd.DataFrame(columns=df.columns)\n",
    "for article in df.article_id.unique():\n",
    "    for system in df.system_id.unique():\n",
    "        ratings = df.loc[(df.article_id == article)&(df.system_id == system), :]\n",
    "        # sanity checks\n",
    "        assert len(ratings) == 3\n",
    "        assert ratings[\"article\"].nunique() == 1\n",
    "        assert ratings[\"summary\"].nunique() == 1\n",
    "        row = ratings.iloc[0].copy()\n",
    "        for col in [\"coherence\", \"fluency\", \"consistency\", \"relevance\"]:\n",
    "            row[col] = ratings[col].mean()\n",
    "        out.loc[len(out)] = row\n",
    "\n",
    "out.to_json(f\"{path}/newsroom-processed.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hanna\n",
    "\n",
    "path = f\"{gdrive_path}/data/hanna\"\n",
    "df = pd.read_csv(f\"{path}/hanna_stories_annotations.csv\")\n",
    "\n",
    "out = pd.DataFrame(columns=[\"id\", \"story_prompt\", \"story\", \"coherence\", \"surprise\", \"complexity\"])\n",
    "for story_id in df[\"Story ID\"].unique():\n",
    "    ratings = df.loc[df[\"Story ID\"] == story_id, :]\n",
    "    # sanity checks\n",
    "    assert len(ratings) == 3\n",
    "    assert ratings[\"Prompt\"].nunique() == 1\n",
    "    assert ratings[\"Story\"].nunique() == 1\n",
    "    row = [ratings[\"Story ID\"].iloc[0], ratings[\"Prompt\"].iloc[0], ratings[\"Story\"].iloc[0]]\n",
    "    for col in [\"Coherence\", \"Surprise\", \"Complexity\"]:\n",
    "        row.append(ratings[col].mean())\n",
    "    out.loc[len(out)] = row\n",
    "\n",
    "out.to_json(f\"{path}/hanna-processed.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summeval\n",
    "\n",
    "path = f\"{gdrive_path}/data/summeval\"\n",
    "df = pd.read_json(f\"{path}/model_annotations.aligned.paired.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "out = pd.DataFrame(columns=[\"article_id\", \"model_id\", \"article\", \"summary\", \"coherence\", \"consistency\", \"fluency\", \"relevance\"])\n",
    "for article_id in df[\"id\"].unique():\n",
    "    summaries = df.loc[df[\"id\"] == article_id, :]\n",
    "    assert summaries[\"model_id\"].nunique() == 16\n",
    "    assert summaries[\"text\"].nunique() == 1\n",
    "    for model_id in summaries[\"model_id\"].unique():\n",
    "        ratings = summaries.loc[summaries[\"model_id\"] == model_id, \"expert_annotations\"].item()\n",
    "        assert len(ratings) == 3\n",
    "        row = [article_id, model_id, summaries[\"text\"].iloc[0]]\n",
    "        row.append(summaries.loc[summaries[\"model_id\"] == model_id, \"decoded\"].item())\n",
    "        for col in [\"coherence\", \"consistency\", \"fluency\", \"relevance\"]:\n",
    "            scores = [r[col] for r in ratings]\n",
    "            avg_score = sum(scores) / len(scores)\n",
    "            row.append(avg_score)\n",
    "        out.loc[len(out)] = row\n",
    "\n",
    "out.to_json(f\"{path}/summeval-processed.jsonl\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pairs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
